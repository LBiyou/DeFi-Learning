name: Find New Flaky Tests

on:
  workflow_call:
    inputs:
      repoUrl:
        required: true
        type: string
        description: 'The URL of the repository to compare changes for detecting flaky tests.'
      projectPath:
        required: true
        type: string
        description: 'The path to the project to run the flaky test detection.'
        default: '.'  
      baseRef:
        required: true
        type: string
        description: 'The base reference or branch to compare changes for detecting flaky tests.'
      headRef:
        required: false
        type: string
        description: 'The head reference or branch to compare changes for detecting flaky tests. Default is the current branch.'  
      runThreshold:
        required: false
        type: string
        description: 'The threshold for the number of times a test can fail before being considered flaky.'
        default: '0.8'
      runWithRace:
        required: false
        type: boolean
        description: 'Run tests with -race flag.'
        default: true
      findByTestFilesDiff:
        required: false
        type: boolean
        description: 'Find new or updated test packages by comparing test files diff.'
        default: true
      findByAffectedPackages:
        required: false
        type: boolean
        description: 'Find new or updated test packages by comparing affected packages.'
        default: true
      slackNotificationAfterTestsChannelId:
        description: "Slack channel ID to send the notification to for failed tests."
        required: false
        type: string
      extraArgs:
        required: false
        type: string
        default: '{}'
        description: 'JSON of extra arguments for the workflow.'
    secrets:
      SLACK_BOT_TOKEN:
        required: false

env:
  GIT_HEAD_REF: ${{ inputs.headRef || github.ref }}
  SKIPPED_TESTS: ${{ fromJson(inputs.extraArgs)['skipped_tests'] || '' }} # Comma separated list of test names to skip running in the flaky detector. Related issue: TT-1823
  MAX_GROUP_SIZE: ${{ fromJson(inputs.extraArgs)['max_group_size'] || '8' }} # The maximum number of jobs to run in parallel when running tests.
  RUN_COUNT: ${{ fromJson(inputs.extraArgs)['run_count'] || '5' }} # The number of times to run the tests to detect flaky tests.

jobs:
  find-tests:
    name: Find Tests To Run
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.split-packages.outputs.matrix }}
      workflow_id: ${{ steps.gen_id.outputs.workflow_id }}
      changed_test_files: ${{ steps.find-changed-test-files.outputs.test_files }}
      affected_test_packages: ${{ steps.find-tests.outputs.packages }}
      git_head_sha: ${{ steps.get_commit_sha.outputs.git_head_sha }}
      git_head_short_sha: ${{ steps.get_commit_sha.outputs.git_head_short_sha }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@9bb56186c3b09b4f86b1c65136769dd318469633 # v4.1.2
        with:
          fetch-depth: 0
          ref: ${{ env.GIT_HEAD_REF }}

      - name: Get commit SHA
        id: get_commit_sha
        run: |
          git_head_sha=$(git rev-parse HEAD)
          git_head_short_sha=$(git rev-parse --short HEAD)
          echo "git_head_sha=$git_head_sha" >> $GITHUB_OUTPUT
          echo "git_head_short_sha=$git_head_short_sha" >> $GITHUB_OUTPUT          

      - name: Set up Go 1.21.9
        uses: actions/setup-go@v5.0.2
        with:
          go-version: '1.21.9'
          cache: false

      - name: Install flakeguard
        shell: bash
        run: go install github.com/smartcontractkit/chainlink-testing-framework/tools/flakeguard@cb4c307f6f0a79a20097129cda7c151d8c5b5d28

      - name: Find new or updated test packages
        id: find-tests
        shell: bash
        env:
          # Needed to run go test -list
          CL_DATABASE_URL: postgresql://postgres@localhost:5432/chainlink_test?sslmode=disable
        run: |
          PATH=$PATH:$(go env GOPATH)/bin
          export PATH

          PACKAGES=$(flakeguard find --find-by-test-files-diff=${{ inputs.findByTestFilesDiff }} --find-by-affected-packages=${{ inputs.findByAffectedPackages }} --base-ref=origin/${{ inputs.baseRef }} --project-path=${{ inputs.projectPath }})
          echo $PACKAGES
          echo "packages=$PACKAGES" >> $GITHUB_OUTPUT

      - name: Find changed test files 
        id: find-changed-test-files
        shell: bash
        env:
          # Needed to run go test -list
          CL_DATABASE_URL: postgresql://postgres@localhost:5432/chainlink_test?sslmode=disable
        run: |
          PATH=$PATH:$(go env GOPATH)/bin
          export PATH

          TEST_FILES=$(flakeguard find --only-show-changed-test-files=true --base-ref=origin/${{ inputs.baseRef }} --project-path=${{ inputs.projectPath }})
          echo $TEST_FILES
          echo "test_files=$TEST_FILES" >> $GITHUB_OUTPUT
          
      - name: Split test packages into groups
        id: split-packages
        if: steps.find-tests.outputs.packages != ''
        shell: bash
        run: |
          PACKAGES=(${{ steps.find-tests.outputs.packages }})
          DESIRED_GROUP_COUNT=$((${{ env.MAX_GROUP_SIZE }}))
          TOTAL_PACKAGES=${#PACKAGES[@]}

          # Number of groups should be no more than the number of packages
          MAX_GROUP_COUNT=$(($TOTAL_PACKAGES < $DESIRED_GROUP_COUNT ? $TOTAL_PACKAGES : $DESIRED_GROUP_COUNT))
          BASE_GROUP_SIZE=$(($TOTAL_PACKAGES / $MAX_GROUP_COUNT))
          EXTRA=$(($TOTAL_PACKAGES % $MAX_GROUP_COUNT))

          groups=()

          current_index=0
          for (( i=0; i < $MAX_GROUP_COUNT; i++ )); do
              # Determine the number of packages for the current group
              group_size=$BASE_GROUP_SIZE
              if [[ $i -lt $EXTRA ]]; then
                  group_size=$(($group_size + 1))
              fi
              
              # Extract the packages for the current group
              if [[ $group_size -gt 0 ]]; then
                  group=("${PACKAGES[@]:current_index:group_size}")
                  groups+=("$(IFS=,; echo "${group[*]}")")
                  current_index=$(($current_index + $group_size))
              fi
          done

          # Convert groups array into a JSON array
          json_groups=$(printf '%s\n' "${groups[@]}" | jq -R . | jq -cs .)
          echo $json_groups
          echo "matrix=$json_groups" >> $GITHUB_OUTPUT

      - name: Generate random workflow id
        id: gen_id
        shell: bash
        run: echo "workflow_id=$(uuidgen)" >> "$GITHUB_OUTPUT"          

  run-tests:
    name: Run Tests
    needs: find-tests
    runs-on: ubuntu-latest
    if: ${{ needs.find-tests.outputs.matrix != '' }}
    strategy:
      fail-fast: false
      matrix: 
        testPackages: ${{ fromJson(needs.find-tests.outputs.matrix) }}
    env:
      DB_URL: postgresql://postgres:postgres@localhost:5432/chainlink_test?sslmode=disable
    steps:
      - name: Checkout repository
        uses: actions/checkout@9bb56186c3b09b4f86b1c65136769dd318469633 # v4.1.2
        with:
          ref: ${{ env.GIT_HEAD_REF }}

      - name: Setup NodeJS
        uses: ./.github/actions/setup-nodejs
        with:
          prod: "true"
      - name: Setup Go
        uses: ./.github/actions/setup-go
        with:
          restore-build-cache-only: "true"
      - name: Setup Solana
        uses: ./.github/actions/setup-solana
      - name: Setup wasmd
        uses: ./.github/actions/setup-wasmd
      - name: Setup Postgres
        uses: ./.github/actions/setup-postgres
      - name: Touching core/web/assets/index.html
        run: mkdir -p core/web/assets && touch core/web/assets/index.html
      - name: Download Go vendor packages
        run: go mod download
      - name: Build binary
        run: go build -o chainlink.test .
      - name: Setup DB
        run: ./chainlink.test local db preparetest
        env:
          CL_DATABASE_URL: ${{ env.DB_URL }}        
      - name: Install LOOP Plugins
        run: |
          pushd $(go list -m -f "{{.Dir}}" github.com/smartcontractkit/chainlink-feeds)
          go install ./cmd/chainlink-feeds
          popd
          pushd $(go list -m -f "{{.Dir}}" github.com/smartcontractkit/chainlink-data-streams)
          go install ./mercury/cmd/chainlink-mercury
          popd
          pushd $(go list -m -f "{{.Dir}}" github.com/smartcontractkit/chainlink-solana)
          go install ./pkg/solana/cmd/chainlink-solana
          popd
          pushd $(go list -m -f "{{.Dir}}" github.com/smartcontractkit/chainlink-starknet/relayer)
          go install ./pkg/chainlink/cmd/chainlink-starknet
          popd

      - name: Go mod tidy
        shell: bash
        run: |
          cd ${{ inputs.projectPath }}
          go mod tidy

      - name: Generate random id
        id: gen_id
        run: echo "id=$(uuidgen)" >> "$GITHUB_OUTPUT"

      - name: Install flakeguard
        shell: bash
        run: go install github.com/smartcontractkit/chainlink-testing-framework/tools/flakeguard@cb4c307f6f0a79a20097129cda7c151d8c5b5d28

      - name: Run tests with flakeguard
        shell: bash
        run: flakeguard run --project-path=${{ inputs.projectPath }} --test-packages=${{ matrix.testPackages }} --run-count=${{ env.RUN_COUNT }} --threshold=${{ inputs.runThreshold }} --race=${{ inputs.runWithRace }} --skip-tests=${{ env.SKIPPED_TESTS }} --output-json=test-result.json
        env:
          CL_DATABASE_URL: ${{ env.DB_URL }}

      - name: Upload test result as artifact
        if: always()
        uses: actions/upload-artifact@v4.4.3
        with:
          name: test-result-${{ needs.find-tests.outputs.workflow_id }}-${{ steps.gen_id.outputs.id }}
          path: test-result.json
          retention-days: 7        

  report:
    needs: [find-tests, run-tests]
    if: always()
    name: Report
    runs-on: ubuntu-latest
    outputs:
      test_results: ${{ steps.set_test_results.outputs.results }}
    steps:
      - name: Set Pretty Project Path
        id: set_project_path_pretty
        run: |
          if [ "${{ inputs.projectPath }}" = "." ]; then
            echo "path=./go.mod" >> $GITHUB_OUTPUT
          else
            echo "path=${{ inputs.projectPath }}/go.mod" >> $GITHUB_OUTPUT
          fi

      - name: Download all test result artifacts
        uses: actions/download-artifact@v4.1.8
        with:
          path: test_results
          pattern:
            test-result-${{ needs.find-tests.outputs.workflow_id }}-*

      - name: Set combined test results
        id: set_test_results
        shell: bash
        run: |
          set -e  # Exit immediately if a command exits with a non-zero status.
          if [ -d "test_results" ]; then
            cd test_results
            ls -R .
            find . -name '*.json' -exec cat {} + | jq -s 'add | sort_by(.PassRatio)' > all_tests.json
            ALL_TESTS_COUNT=$(jq 'length' all_tests.json)
            echo "All tests count: $ALL_TESTS_COUNT"
            echo "all_tests_count=$ALL_TESTS_COUNT" >> "$GITHUB_OUTPUT"
            jq -c 'map(select(.PassRatio < ($runThreshold | tonumber) and .Skipped != true)) | map(.PassRatio |= (. * 100 | tostring + "%"))' all_tests.json --arg runThreshold '${{ inputs.runThreshold }}' > failed_tests.json
            FAILED_TESTS_COUNT=$(jq 'length' failed_tests.json)
            echo "Failed tests count: $FAILED_TESTS_COUNT"
            echo "failed_tests_count=$FAILED_TESTS_COUNT" >> "$GITHUB_OUTPUT"
          else
            echo "No test results directory found."
            echo "all_tests_count=0" >> "$GITHUB_OUTPUT"
            echo "failed_tests_count=0" >> "$GITHUB_OUTPUT"
          fi

      - name: Calculate Flakiness Threshold Percentage
        id: calculate_threshold
        run: |
          threshold_percentage=$(echo '${{ inputs.runThreshold }}' | awk '{printf "%.0f", $1 * 100}')
          echo "threshold_percentage=$threshold_percentage" >> $GITHUB_OUTPUT          

      - name: Upload Failed Test Results as Artifact
        if: ${{ fromJson(steps.set_test_results.outputs.failed_tests_count) > 0 }}
        uses: actions/upload-artifact@v4.4.3
        with:
          name: failed_tests.json
          path: test_results/failed_tests.json
          retention-days: 7        

      - name: Create ASCII table with failed test results
        if: ${{ fromJson(steps.set_test_results.outputs.failed_tests_count) > 0 }}
        shell: bash
        run: |
          jq -r '["TestPackage", "TestName", "PassRatio", "RunCount", "Skipped"], ["---------", "---------", "---------", "---------", "---------"], (.[] | [.TestPackage, .TestName, .PassRatio, .Runs, .Skipped]) | @tsv' test_results/failed_tests.json | column -t -s$'\t' > test_results/failed_tests_ascii.txt
          cat test_results/failed_tests_ascii.txt

      - name: Create ASCII table with all test results
        if: ${{ fromJson(steps.set_test_results.outputs.all_tests_count) > 0 }}
        shell: bash
        run: |
          jq -r '["TestPackage", "TestName", "PassRatio", "RunCount", "Skipped"], ["---------", "---------", "---------", "---------", "---------"], (.[] | [.TestPackage, .TestName, .PassRatio, .Runs, .Skipped]) | @tsv' test_results/all_tests.json | column -t -s$'\t' > test_results/all_tests_ascii.txt
          cat test_results/all_tests_ascii.txt

      - name: Create GitHub Summary
        run: |
          echo "## Flaky Test Detection Summary" >> $GITHUB_STEP_SUMMARY
          echo "### Comparative Test Analysis" >> $GITHUB_STEP_SUMMARY
          echo "Checked changes between \`${{ inputs.baseRef }}\` and \`${{ env.GIT_HEAD_REF }}\` for ${{ steps.set_project_path_pretty.outputs.path }} project. See all changes [here](${{ inputs.repoUrl }}/compare/${{ inputs.baseRef }}...${{ needs.find-tests.outputs.git_head_sha }}#files_bucket)." >> $GITHUB_STEP_SUMMARY

      - name: Append Changed Test Files to GitHub Summary
        if: ${{ needs.find-tests.outputs.changed_test_files != '' && inputs.findByTestFilesDiff && !inputs.findByAffectedPackages }}
        run: |
          echo "### Changed Test Files" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          IFS=' ' read -ra ADDR <<< "${{ needs.find-tests.outputs.changed_test_files }}"
          for file in "${ADDR[@]}"; do
            echo "$file" >> $GITHUB_STEP_SUMMARY
          done
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Append Affected Test Packages to GitHub Summary
        if: ${{ needs.find-tests.outputs.affected_test_packages != '' }}
        run: |
          echo "### Affected Test Packages" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          IFS=' ' read -ra ADDR <<< "${{ needs.find-tests.outputs.affected_test_packages }}"
          for package in "${ADDR[@]}"; do
            echo "$package" >> $GITHUB_STEP_SUMMARY
          done
          echo '```' >> $GITHUB_STEP_SUMMARY

      - name: Read Failed Tests File
        if: ${{ fromJson(steps.set_test_results.outputs.failed_tests_count) > 0 }}
        id: read_failed_tests
        run: |
          file_content=$(cat test_results/failed_tests_ascii.txt)
          echo "failed_tests_content<<EOF" >> $GITHUB_OUTPUT
          echo "$file_content" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Append Failed Tests to GitHub Summary
        if: ${{ fromJson(steps.set_test_results.outputs.failed_tests_count) > 0 }}
        run: |
          threshold_percentage=$(echo "${{ inputs.runThreshold }}" | awk '{printf "%.0f", $1 * 100}')
          echo "### Failed Tests :x:" >> $GITHUB_STEP_SUMMARY
          echo "Ran \`${{ steps.set_test_results.outputs.all_tests_count }}\` tests in total for all affected test packages. Below are the tests identified as flaky, with a pass ratio lower than the \`${threshold_percentage}%\` threshold:" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat test_results/failed_tests_ascii.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "For detailed logs of the failed tests, please refer to the 'failed_tests.json' file in the Artifacts section at the bottom of the page." >> $GITHUB_STEP_SUMMARY

      - name: Append Success Note if All Tests Passed
        if: ${{ fromJson(steps.set_test_results.outputs.all_tests_count) > 0 && fromJson(steps.set_test_results.outputs.failed_tests_count) == 0 }}
        run: |
          echo "### All Tests Passed! :white_check_mark:" >> $GITHUB_STEP_SUMMARY
          echo "Ran \`${{ steps.set_test_results.outputs.all_tests_count }}\` tests in total and found no flakes." >> $GITHUB_STEP_SUMMARY

      - name: Append Additional Info to GitHub Summary
        if: ${{ fromJson(steps.set_test_results.outputs.all_tests_count) > 0 }}
        run: |
          echo "### Settings" >> $GITHUB_STEP_SUMMARY
          threshold_percentage=$(echo "${{ inputs.runThreshold }}" | awk '{printf "%.0f", $1 * 100}')
          echo "| **Setting**             | **Value**  |" >> $GITHUB_STEP_SUMMARY
          echo "|-------------------------|------------|" >> $GITHUB_STEP_SUMMARY
          echo "| Flakiness Threshold     | ${threshold_percentage}%       |" >> $GITHUB_STEP_SUMMARY
          echo "| Test Run Count          | ${{ env.RUN_COUNT }}         |" >> $GITHUB_STEP_SUMMARY
          echo "| Race Detection          | ${{ inputs.runWithRace }}      |" >> $GITHUB_STEP_SUMMARY
          echo "| Excluded Tests          | ${{ env.SKIPPED_TESTS }}      |" >> $GITHUB_STEP_SUMMARY
          
      - name: Append No Tests Found Message to GitHub Summary
        if: ${{ fromJson(steps.set_test_results.outputs.all_tests_count) == 0 }}
        run: |
          echo "### No Tests To Execute" >> $GITHUB_STEP_SUMMARY
          echo "No updated or new tests found for \`${{ steps.set_project_path_pretty.outputs.path }}\` project. The flaky detector will not run." >> $GITHUB_STEP_SUMMARY

      - name: Post comment on PR if flaky tests found
        if: ${{ fromJson(steps.set_test_results.outputs.failed_tests_count) > 0 && github.event_name == 'pull_request' }}
        uses: actions/github-script@v7
        env:
          MESSAGE_BODY_1: '### Flaky Test Detector for `${{ steps.set_project_path_pretty.outputs.path }}` project has failed :x:'
          MESSAGE_BODY_2: 'Ran new or updated tests between `${{ inputs.baseRef }}` and ${{ needs.find-tests.outputs.git_head_sha }} (`${{ env.GIT_HEAD_REF }}`).'
          MESSAGE_BODY_3: ${{ format('[View Flaky Detector Details]({0}/{1}/actions/runs/{2}) | [Compare Changes]({3}/compare/{4}...{5}#files_bucket)', github.server_url, github.repository, github.run_id, inputs.repoUrl, github.base_ref, needs.find-tests.outputs.git_head_sha) }}
          MESSAGE_BODY_4: '#### Failed Tests'
          MESSAGE_BODY_5: 'Ran ${{ steps.set_test_results.outputs.all_tests_count }} tests in total for all affected test packages. Below are the tests identified as flaky, with a pass ratio lower than the ${{ steps.calculate_threshold.outputs.threshold_percentage }}% threshold:'
          MESSAGE_BODY_6: '```'
          MESSAGE_BODY_7: '${{ steps.read_failed_tests.outputs.failed_tests_content }}'
          MESSAGE_BODY_8: '```'
        with:
          script: |
            const prNumber = context.payload.pull_request.number;

            const commentBody = `${process.env.MESSAGE_BODY_1}

            ${process.env.MESSAGE_BODY_2}

            ${process.env.MESSAGE_BODY_3}

            ${process.env.MESSAGE_BODY_4}

            ${process.env.MESSAGE_BODY_5}

            ${process.env.MESSAGE_BODY_6}
            ${process.env.MESSAGE_BODY_7}
            ${process.env.MESSAGE_BODY_8}`;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              body: commentBody
            });

      - name: Send Slack message
        uses: slackapi/slack-github-action@6c661ce58804a1a20f6dc5fbee7f0381b469e001 # v1.25.0
        if: ${{ inputs.slackNotificationAfterTestsChannelId != '' && fromJson(steps.set_test_results.outputs.all_tests_count) > 0 }}
        id: slack
        env:
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        with:
          channel-id: ${{ inputs.slackNotificationAfterTestsChannelId }}
          payload: |
            {
              "attachments": [
                {
                  "color": "${{ contains(join(needs.*.result, ','), 'failure') && '#C62828' || contains(join(needs.*.result, ','), 'cancelled') && '#FFA000' || '2E7D32' }}",
                  "blocks": [
                    {
                      "type": "section",
                      "text": {
                        "type": "mrkdwn",
                        "text": "Flaky Test Detector for ${{ steps.set_project_path_pretty.outputs.path }} project - ${{ contains(join(needs.*.result, ','), 'failure') && 'Failed :x:' || contains(join(needs.*.result, ','), 'cancelled') && 'Was cancelled :warning:' || 'Passed :white_check_mark:' }}"
                      }
                    },
                    {
                      "type": "section",
                      "text": {
                        "type": "mrkdwn",
                        "text": "Ran changed tests between `${{ inputs.baseRef }}` and `${{ needs.find-tests.outputs.git_head_short_sha }}` (`${{ env.GIT_HEAD_REF }}`)."
                      }
                    },
                    {
                      "type": "section",
                      "text": {
                        "type": "mrkdwn",
                        "text": "${{ format('<{0}/{1}/actions/runs/{2}|View Flaky Detector Details> | <{3}/compare/{4}...{5}#files_bucket|Compare Changes>{6}', github.server_url, github.repository, github.run_id, inputs.repoUrl, inputs.baseRef, needs.find-tests.outputs.git_head_sha, github.event_name == 'pull_request' && format(' | <{0}|View PR>', github.event.pull_request.html_url) || '') }}"
                      }
                    }                 
                  ]
                }
              ]
            }
